---
layout: post
mathjax: true
title:  "Variational Autoencoders"
author: "Sandro Cavallari"
tag: "Variational Autoencoders"
comments_id: 9
---

In this post, I will explore the theory behind Variational Autoencoders (VAE). The code to used for both CNN and normal feedforward autoencoder trained on MNIST dataset is vailable on my [github](https://github.com/andompesta/variational-autoencoder/tree/master).

VAEs are generative models rooted in Bayesian inference theory and Variational inference. The idea is to generate a data-points from a given latent variable that encode the type of data we want to generate. For example, say, we want to generate an animal. First, we imagine the animal: it must have four legs, and it must be able to swim. Having those criteria, we could then actually generate the animal by sampling from the animal kingdom. 

Let use define some notation:
 - $x_i$ is a datapoint
 - $z$ is a latent variable
 - $p(x_i)$ is the probability distribution of the data
 - $p(z)$ is the probability of the latent variable indicating the type of data generated
 - $p(x_i|z)$ represents the distribution of the generated based on a latent variable. According to our analogy it is like turning imagination into reality.
 - $I(x_i) = - \log p(x_i)$ as the **Information** associated to an event
 - $H(X) = \sum_{x_i \in X} p(x_i) \log p(x_i)$ is the **Entropy** or the average information contained in an event
 - $D_{KL}\big(p(X) || q(X)\big) = \sum_{x_i \in X} p(x_i) \log \frac{p(x_i)}{q(x_i)} = - \sum_{x_i \in X} p(x_i) \log \frac{q(x_i)}{p(x_i)}$ is the **KL divergence** between two discrete distributions.

KL divergence has some notable properties: first of all $D_{KL}\big(p(X) || q(X)\big)$ is NOT equal to $D_{KL}\big(q(X) || p(X)\big)$; in other words, it is an assimetric function. In second place, $D_{KL} > 0$.

Variational Autoencoders are a generative model; meaning that we will be able to sample new datapoints from such a model.
In genearal, generative models learn a functional form of $P(X)$ such that we can sample from. 
However, $p(X)$ is unknown in most cases and only some samples from $p(X)$ are provided; i.e. a dataset $({x_i})_{i=1}$.
VAEs overcome this limitation by exploiting the the idea that high dimentional data is generated based on a low dimentional lavent variable $z_i$; thus the joint distribution can be factorized as $p(x, z) = p(x|z) p(z)$.
Finally, by marginalization we can the define $p(x)$ as:
$$ 
p(x) = \int p(x|z) p(z) \partial z.
$$

According to our previous analogy, $z$ represent the immagined conspet, while $x$ it is the realization of all the consepts selected.
As overmentioned, at training time we are neither given access to $p(x)$ nor to the latent variable $z$ used to generate our dataset.
Yet during the training phase of a VEAs, we are going to the learn a resonable posterior distribution $p(z|x)$.
This make a lot of sense: we want to make our latent variable likely under our data so to generate plausible data.
<!-- 
 ![equation](https://latex.codecogs.com/gif.latex?%5Clarge%20p%28z%7Cx_i%29). 
Assuming to know the such posterior, we can infer our latent variable distribution ![equation](https://latex.codecogs.com/gif.latex?%5Clarge%20p%28z%29) by marginalisation over our dataset.  -->
 
According to Bayesian theory:

$$
p(z|x) = \frac{p(x|z)\cdot p(z)}{p(x)} = \frac{p(x, z)}{p(x)}.
$$
As abovementioned $p(x)$ be expressed as  marginalization over $z$, however such computation is usually intractable as we need to integrate over all the latent dimentions:
$$
p(x) \int ... \int \int p(x|z)\cdot p(z) \partial z_i.
$$

To overcome such limitation, variational inference suggests to **approximate** $p(z|x)$ by a simpler distribution $q(z|x)$. 
By giving to $q(z|x)$ a tractable form (Gaussian exponential) and "play" with its parameters so to match $p(z|x)$ as closes as possible.

Formally, we can rewrite our goal as:
$$
\begin{align*}
\min D_{KL}\big(q(z|x) || p(z|x)\big) & = - \sum_{x \in \hat{X}} q(z|x) \log \frac{p(z|x)}{q(z|x)}  \\
& = - \sum_{x \in \hat{X}} q(z|x) \log \Big(\frac{p(x, z)}{q(z|x)}  \cdot \frac{1}{p(x)} \Big) \\
& = - \sum_{x \in \hat{X}} q(z|x) \log \Big(\frac{p(x, z)}{q(z|x)}  - \log p(x) \Big)  \\
& = - \sum_{x \in \hat{X}} q(z|x) \log \frac{p(x, z)}{q(z|x)} + \sum_{x \in \hat{X}} q(z|x) \log p(x) \\
& = \log p(x) - \sum_{x \in \hat{X}} q(z|x) \log \frac{p(x, z)}{q(z|x)} ~~~~ \small{\text{\textcolor{red}{as $\sum_{x \in \hat{X}} q(z|x) = 1$ and $p(x)$ do not depend on $z$}}}
\end{align*}
$$

By rearranging the above equation we can state that:
$$
\log p(x) = D_{KL}\big(q(z|x) || p(z|x)\big) + \sum_{x \in \hat{X}} q(z|x) \log \frac{p(x, z)}{q(z|x)}.
$$
However, $p(x)$ is constant for a given dataset $\hat{X}$, thus minimizing $D_{KL}\big(q(z|x) || p(z|x)\big)$ is equivalent to maximise $\sum_{x \in \hat{X}} q(z|x) \log \frac{p(x, z)}{q(z|x)}$ up to a constant factor. Such formulation of the KL-divergenve is also known as the Evidence Lower Bound (ELBO) and it is tractable:

$$
\begin{align*}
\sum_{x \in \hat{X}} q(z|x) \log \frac{p(x, z)}{q(z|x)} & = \sum_{x \in \hat{X}} q(z|x) \log \big( \frac{p(x|z) p(z)}{q(z|x)}\big)  \\
& = \sum_{x \in \hat{X}} q(z|x) \Big(\log p(x|z) + \log \frac{p(z)}{q(z|x)} \Big)  \\
& = \sum_{x \in \hat{X}} q(z|x) \log p(x|z) + \sum_{x \in \hat{X}} q(z|x) \log \frac{p(z)}{q(z|x)} \\
& = \mathbb{E}_{z \sim q(z|x)} \big[ \log p(x|z) \big] - \sum_{x \in \hat{X}} q(z|x) \log \frac{q(z|x)}{p(z)} \\
& = \mathbb{E}_{z \sim q(z|x)} \big[ \log p(x|z) \big] - \mathbb{E}_{z \sim q(z|x)} \big[ \log q(z|x) - \log p(z) \big]
\end{align*}
$$

The initial component of the ELBO, denoted as $\mathbb{E}_{z \sim q(z|x)} \big[ \log p(x|z) \big]$, is commonly known as the (negative) reconstruction error. This is because it involves encoding $x$ into $z$ and then decoding it back. The second segment of the, $\mathbb{E}_{z \sim q(z|x)} \big[ \log q(z|x) - \log p(z) \big]$, can be viewed as a regularization term that imposes a specific distribution on $q$ such as the Normal distribution.

## Results
Based on the code, we have trained a CNN-based Variational Autoencoder on the MNIST dataset.
[Fig.1](#fig:loss) report the training loss, while [Fig.2](#fig:new-example) shows us some generated example.
As it is possible to see, there are still some artifact. Maybe a better activation function would provide better results.

<figure>
    <img src="{{site.baseurl}}/assets/img/vea/loss.png" style="max-width: 90%">
    <figcaption style="font-size:small;">
        Figure 1: Training loss of a CNN based VAE on the MNIST dataset.
    </figcaption>
</figure>

<figure>
    <img src="{{site.baseurl}}/assets/img/vea/cnn_variational_autoencoder_pred.png" style="max-width: 90%">
    <figcaption style="font-size:small;">
        Figure 2: Generated examples.
    </figcaption>
</figure>
