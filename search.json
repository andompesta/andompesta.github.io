[
  {
    "objectID": "posts/gradient_descent_and_backprop/index.html",
    "href": "posts/gradient_descent_and_backprop/index.html",
    "title": "Gradinet Descent and Backpropagation",
    "section": "",
    "text": "Most deep learning algorithm relay on the idea of learning some useful information from the data to solve a specific task. That is, instead of explicitly define every single instruction that a program has to perform, in machine learning, we specify an optimization routine that a program executes over a set of examples to improve its performances. By executing the optimization algorithm, a machine automatically navigates the solution space to find the best “program” that solve the given task starting from a random state: \\(\\mathbf{\\theta}\\). It is expectable that the initial program obtained based on the random state would not perform well on the chosen task, however, by iterating over the dataset, we can adjust \\(\\mathbf{\\theta}\\) until we obtain an optimal solution.\n\nGradient Descent\nOne of the most common learning algorithm is known as Gradient Descent or Stochastic Gradient Descent (SGD) [1]. The core idea of SGD is to iteratively evaluate the difference between the obtained prediction of the model (\\(y_{\\theta}\\)), and, the desired output (\\(y\\)) utilizing a loss function \\(\\mathcal{L}(y_{\\mathbf{\\theta}}, y)\\). Once the difference is known, it is possible to adjust \\(\\theta\\) to reduce the difference or prediction error.\nFormally, SGD is composed of 3 main steps:\n\nevaluate the loss function: \\(\\mathcal{L}(y_{\\mathbf{\\theta}}, y)\\),\ncompute the gradient of the loss function w.r.t. the model parameters: \\(\\nabla \\mathcal{L}_{\\theta} = \\frac{\\partial \\mathcal{L}(y_{\\theta}, y)}{\\partial \\theta}\\),\nupdate the model parameters (or solution) to decrease the loss function: \\(\\mathbf{\\theta} = \\mathbf{\\theta} - \\eta \\nabla \\mathcal{L}_{\\theta}\\).\n\nAs it is possible to notice, such a learning algorithm requires a loss function that is continuous and differentiable; otherwise, it is not applicable. However, over the years, many efficient and effective loss functions have been proposed.\n\n\nBackpropagation\nComputing the analytical gradients for a deep learning algorithm might not be easy, and it is definitely an error-prone procedure. Luckily, over the years mathematicians manage to programmatically compute the derivate of most of the functions with a procedure known as algorithmic differentiation. The application of algorithmic differentiation to compute the SGD is known as backpropagation.\nSupposing to have the current function \\(f(x,y,z) = (x + y) \\cdot z\\). It is possible to simplify it’s computation defining an intermediate function:\n\\[\nq(x, y) = x + y \\Rightarrow f(q, z) = q \\cdot z.\n\\]\nKnowing that:\n\n\\(\\frac{\\partial f}{\\partial q} = z\\)\n\\(\\frac{\\partial f}{\\partial z} = q\\)\n\\(\\frac{\\partial q}{\\partial x} = 1\\)\n\\(\\frac{\\partial q}{\\partial y} = 1\\)\n\nwe can compute \\(\\frac{\\partial f}{\\partial x}\\) by chain rule:\n\\[\n\\frac{\\partial f}{\\partial x} = \\frac{\\partial f}{\\partial q} \\cdot \\frac{\\partial q}{\\partial x}.\n\\]\nThis operation can be seen even as a computational graph, where each node represent an operation ; and using backpropagation it is possible to compute the gradient of function \\(f\\) w.r.t. its input variable \\(x\\) and \\(y\\):\n\n\n\n\n\n\n\n\n\n\nFigure 1: The forward and backward pass of the computational graph for the function $ f(x,y,z) = (x + y) z $. (Image taken from Andrej Karpathy slides, CS231n.)\n\n\n\nIt has to be noted that, backpropagation is a local and global process. It is local since a gate, during the forward pass, can compute:\n\nits output value: \\(q = x + y = 3\\),\nas well as its local gradient (the gradient of its input w.r.t. its output): \\(\\frac{\\partial q}{\\partial x} = 1\\) and \\(\\frac{\\partial q}{\\partial y} = 1\\).\n\nIt is global since, a gate need to know the gradient of its output node in order to evaluate the chain rules: \\(\\frac{\\partial f}{\\partial q}\\). The gradient of its ouput is known only during the backward pass, thus all the local computations need to be stored in memory; thus require a lot of memory.\nThe backward pass start by computing: \\(\\frac{f}{\\partial f} = 1\\). Then, knowing that \\(\\frac{\\partial f}{\\partial q} = z\\) and \\(\\frac{\\partial f}{\\partial q} = \\frac{f}{\\partial f} \\frac{\\partial f}{\\partial q} = 1 \\cdot -4 = -4\\). Similarly, \\(\\frac{\\partial f}{\\partial z} = q\\) and \\(\\frac{\\partial f}{\\partial z} = \\frac{f}{\\partial f} \\frac{\\partial f}{\\partial z} = 3\\). Finally, our goal is to goal is to compute: \\[\n\\frac{\\partial f}{\\partial x} = \\frac{\\partial f}{\\partial q} \\frac{\\partial q}{\\partial x} = -4 \\cdot 1 = -4\n\\] and, \\[\n\\frac{\\partial f}{\\partial y} = \\frac{\\partial f}{\\partial q} \\frac{\\partial q}{\\partial y} = -4 \\cdot 1 = -4\n\\].\n\n\nWeight Decay\nTo achieve better generaliation performance it is well known that graient updates needs to be regularized so to have sparse or force small weights magnitude. The two most common regularizations for gradiens are L1-regularization or weight decay [2] (equivalent to the L2-regularization):\n\\[\n\\theta_{t+1} = \\theta_t - \\alpha \\frac{\\partial f(x; \\theta_t)}{\\partial \\theta_t} - \\lambda \\theta_t\n\\]\nwhere \\(\\lambda \\theta_t\\) stand for weight decay or L2-regularization. However, weight dacay and L2-regularization are equivalent only for SDG, but not for Adam or other adaptive optimizers. Instead of applying the same learning rate to all parameters, Adam apply a different learning rate to each parameters proportional to the update signals they recently recevied (a.k.a proportional to the recent gradients). As Adam uses a different learning rate per each parameters, it means that L2-regularization is not only affected by \\(\\lambda\\) but also from the learning rate and the momentum. Thus, Adam requires a bigger regularizer coefficent to achieve comparable performance as SGD.\n\n\nReferences\n\n\n1. Hanson S, Pratt L (1988) Comparing biases for minimal network construction with back-propagation. Advances in neural information processing systems 1\n\n\n2. Gugger S, Howard J Fast.ai - AdamW and Super-convergence is now the fastest way to train neural nets — fast.ai"
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Posts",
    "section": "",
    "text": "Basic Principles of Linear Algebra\n\n\n\n\n\n\nLinear Algebra\n\n\n\n\n\n\n\n\n\nDec 23, 2020\n\n\nSandro Cavallari\n\n\n\n\n\n\n\n\n\n\n\n\nGradinet Descent and Backpropagation\n\n\n\n\n\n\nDeep Learning\n\n\n\n\n\n\n\n\n\nDec 22, 2020\n\n\nSandro Cavallari\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "This is my personal space where I keep all my notes from my ML experience. I’m mostly interested in NLP and graph embeddings/analytics. Thus expect most of the material to cover:\n\nFundamentals of Deep Learning;\nFundamentals of Reinforcement Learning;\nBasic Stats;\nBasic of Neural ODE.\n\nPlease note that this website is ment to keep only my personal material, this it my contains errors and typos.\n\nHere are some working principles I try to apply during my working expeience.\n\n\n\nThe Skunk Works workers must be delegated practically complete control of his program in all aspects.\nThe number of people having any connection with the project must be restricted in an almost vicious manner. Use a small number of good people (10% to 25% compared to the so-called normal systems).\nA very simple drawing and drawing release system with great flexibility for making changes must be provided.\nThere must be a minimum number of reports required, but important work must be recorded thoroughly.\nAccess by outsiders to the project and its personnel must be strictly controlled by appropriate security measures.\nBecause only a few people will be used in engineering and most other areas, ways must be provided to reward good performance by pay not based on the number of personnel supervised.\n\n\n\n\n\nMake the requirements less dumb. “Your requirements are definitely dumb, it does not matter who gave them to you.” Uses this step to test assumptions and question-the-question, especialy if it come from a ‘smart person’ since you might not question them enough.\nDelete the part or process. “If you’re not adding things back in at least 10% of the time, you’re clearly not deleting enough.” Starting lean and building up when and if required, but be strongly bias throward removing thinks. Each requirement or constraint must be accountable to a person, so you can ask that person about its relevance and purpose.\nSimplify or optimise the design. “Possibly the most common error of a smart engineer is to optimise a thing that should not exist”. Do your work and go through the first two steps before trying to optimise. To do this effectively you need an holistic view of the project and you need to consider the overall cost-benefit for a more complicated design.\nAccelerate cycle time. “Try a bunch of things, and do more of what works”. Once you have find the right direction is time to accelerate the lifecycle. Aim for an experiment a day. Note that, it is extreamly importanto to do the first 3 steps before as “if you’re digging your grave, don’t dig faster.”"
  },
  {
    "objectID": "index.html#my-vision-of-skunkworks-rules",
    "href": "index.html#my-vision-of-skunkworks-rules",
    "title": "Welcome",
    "section": "",
    "text": "The Skunk Works workers must be delegated practically complete control of his program in all aspects.\nThe number of people having any connection with the project must be restricted in an almost vicious manner. Use a small number of good people (10% to 25% compared to the so-called normal systems).\nA very simple drawing and drawing release system with great flexibility for making changes must be provided.\nThere must be a minimum number of reports required, but important work must be recorded thoroughly.\nAccess by outsiders to the project and its personnel must be strictly controlled by appropriate security measures.\nBecause only a few people will be used in engineering and most other areas, ways must be provided to reward good performance by pay not based on the number of personnel supervised."
  },
  {
    "objectID": "index.html#musks-development-principles",
    "href": "index.html#musks-development-principles",
    "title": "Welcome",
    "section": "",
    "text": "Make the requirements less dumb. “Your requirements are definitely dumb, it does not matter who gave them to you.” Uses this step to test assumptions and question-the-question, especialy if it come from a ‘smart person’ since you might not question them enough.\nDelete the part or process. “If you’re not adding things back in at least 10% of the time, you’re clearly not deleting enough.” Starting lean and building up when and if required, but be strongly bias throward removing thinks. Each requirement or constraint must be accountable to a person, so you can ask that person about its relevance and purpose.\nSimplify or optimise the design. “Possibly the most common error of a smart engineer is to optimise a thing that should not exist”. Do your work and go through the first two steps before trying to optimise. To do this effectively you need an holistic view of the project and you need to consider the overall cost-benefit for a more complicated design.\nAccelerate cycle time. “Try a bunch of things, and do more of what works”. Once you have find the right direction is time to accelerate the lifecycle. Aim for an experiment a day. Note that, it is extreamly importanto to do the first 3 steps before as “if you’re digging your grave, don’t dig faster.”"
  },
  {
    "objectID": "posts/linear_algebra/index.html",
    "href": "posts/linear_algebra/index.html",
    "title": "Basic Principles of Linear Algebra",
    "section": "",
    "text": "Linear algebra is the branch of math and statistics that is devoted to the study of matrices and vectors. As such, it is broadly used to model real-world problems in phisitcs and machine learning. Such post is a collections of my notes obtained from the 3Blue1Brown series on linear-algebra [1] and Murphy’s new book [2]."
  },
  {
    "objectID": "posts/linear_algebra/index.html#eigendecomposition",
    "href": "posts/linear_algebra/index.html#eigendecomposition",
    "title": "Basic Principles of Linear Algebra",
    "section": "Eigendecomposition",
    "text": "Eigendecomposition\nGiven a squared matrix \\(A \\in \\mathbb{R}^{n \\times n}\\), it is possible to rewrite Eq. \\(\\ref{eq:eigenvectors}\\) in matrix form as:\n$ \\[\\begin{equation}\n\\label{eq:eigenvectors_matrix}\nA \\rmU = \\rmU \\mathbf{\\Lambda}\n\\end{equation}\\] $\nMoreover, according to Eq. \\(\\ref{eq:cob}\\), using the eigenvectors of \\(A\\) as new basis of \\(A\\) will generate a diagonal matrix of eigenvalues:\n$ \\[\\begin{equation}\n\\rmU^{-1} A \\rmU = \\mathbf{\\Lambda}\n\\end{equation}\\] $\nwhere \\(\\rmU \\in \\mathbb{R}^{n \\times n} = \\left[\\begin{array}{ccc}\n  | & | & | \\\\\n  \\rve_1 & \\dots & \\rve_{n}\\\\\n  | & | & | \\\\\n\\end{array}\\right]\\) is the matrix formed by the eigenvectors of \\(A\\) and \\(\\mathbf{\\Lambda} \\in \\mathbb{R}^{n \\times n} = \\left[\\begin{array}{ccc}\n  \\lambda_1 &  &  \\\\\n   & \\ddots & \\\\\n   & & \\lambda_n \\\\\n\\end{array}\\right]\\) is the diagonal matrix formed by the eigenvalues assogiated to the eigenvectors of \\(A\\).\nThis process of expressing \\(A\\) in terms of its eigenvalue and eigenvectors is know as diagonalization. If the eigenvalues of \\(A\\) are linearly indipendent, then the matrix \\(\\rmU\\) is invertible, thus, it is possible to decompose \\(A\\) as:\n$ \\[\\begin{equation}\n\\label{eq:eigendecomposition}\nA = \\rmU \\mathbf{\\Lambda} \\rmU^{-1} .\n\\end{equation}\\] $\nMoreover, if \\(A\\) is real valued and symmetric then it can be shown that \\(\\rmU\\) is orthonormal, i.e., \\(\\rvu^T_i \\rvu_j = 0\\) if \\(i \\neq j\\) and \\(\\rvu^T_i \\rvu_i = 1\\) (or \\(\\rmU^T\\rmU = \\rmU \\rmU^T = \\rmI\\)). Thus, we can futher symplify Eq. \\(\\ref{eq:eigendecomposition}\\) \\(A\\) as:\n$ \\[\\begin{equation}\nA = \\rmU \\mathbf{\\Lambda} \\rmU^T .\n\\end{equation}\\] $\nAs a final note, it is possible to leverage such eigendecomposition to easily compute the inverse of a matrix \\(A\\). Since \\(\\rmU^T = \\rmU^{-1}\\), we have:\n$ \\[\\begin{equation}\nA^{-1} = \\rmU \\mathbf{\\Lambda}^{-1} \\rmU^T .\n\\end{equation}\\] $\n\nLagrangian Methods for Constrained Optimization\nWhile eigen decomposition is commonly applied to solve systems of liear equations. It is also a powerful method for optimization subject to linear constrains (constrained optimization). That is, it can be used to solve quadratic constrained problems of the form:\n$ _{} ^T + d, ~~ ~~ ^T - 1 = 0 $\nwhere \\(\\rmH \\in \\mathbb{R}^{n \\times n}\\) is symmetric. Such problems are a specific instanche of the Lagrangian method, in which an augmented objective is created to ensure the constrain satisfability:\n$ L(, ) = {} {} ^T + d - (^T - 1) $\nThe optimal \\(\\rvx^*\\) that solve the problem, need to satisfy the zero-gradient condition:\n$ \\[\\begin{align*}\n\\frac{\\partial L(\\rvx, \\lambda)} {\\partial \\rvx} & = 0 \\\\\n& = \\frac{ \\partial } {\\partial \\rvx} \\rvx^T \\rmH \\rvx   +  \\frac{\\partial}{\\partial \\rvx} d - \\frac{\\partial}{\\partial \\rvx} \\lambda (\\rvx^T \\rvx - 1)  \\\\\n& = \\rvx^T (\\rmH + \\rmH^T) + 0 - 2 \\lambda \\rvx^T  && { \\small \\rmH = \\rmH^T \\text{ since is symmetric.} }\\\\\n& = 2 \\rvx^T \\rmH - 2 \\lambda \\rvx^T \\\\\n\\frac{\\partial L(\\rvx, \\lambda)} {\\partial \\lambda} & = 0  \\\\\n& =  \\frac{ \\partial }{ \\partial \\lambda } \\rvx^T \\rmH \\rvx + \\frac{ \\partial }{ \\partial \\lambda } d - \\frac{ \\partial }{ \\partial \\lambda } \\lambda (\\rvx^T \\rvx - 1) \\\\\n& = 0 + 0 - \\rvx^T \\rvx + 1 \\\\\n& = \\rvx^T \\rvx - 1\n\\end{align*}\\] $\nwhich is equivalent to the eigenvector equation (Eq. \\(\\ref{eq:eigenvectors_matrix}\\)) $ = $."
  },
  {
    "objectID": "posts/linear_algebra/index.html#singular-value-decomposition-svd",
    "href": "posts/linear_algebra/index.html#singular-value-decomposition-svd",
    "title": "Basic Principles of Linear Algebra",
    "section": "Singular Value Decomposition (SVD)",
    "text": "Singular Value Decomposition (SVD)\nWhile eigendecomposition require squared matrices, SVD allow the factorization of rectangular matrices into singular vectors and singular values. Given any \\(A \\in \\mathbb{R}^{m \\times n}\\), it is possible to depompose it as:\n$ \\[\\begin{equation}\nA = \\rmU \\rmS \\rmV^T\n\\end{equation}\\] $\nwhere \\(\\rmU \\in \\mathbb{R}^{m \\times m}\\) is composed by orthonormal columns (\\(\\rmU^T \\rmU = \\rmI\\)), \\(\\rmV \\in \\mathbb{R}^{n \\times n}\\) is compesed by orthonormals rows and columns (\\(\\rmV^T\\rmV = \\rmV \\rmV^T = \\rmI\\)), and \\(\\rmS \\in \\mathbb{R}^{m \\times n}\\) is a diagonal matrix containing the singular values \\(\\sigma_i \\geq 0\\). \\(\\rmU\\) and \\(\\rmV^T\\) are respectively known as the left singular vectors and right singular vectors of \\(A\\) and are obtained as the eigenvectors of \\(AA^T\\) and \\(A^TA\\). Similarly, \\(\\rmS\\) is composed by the squared root of the eigenvalues of \\(AA^T\\) and \\(A^TA\\) arranged in descending order.\nFor example, consider\n$ A = $\nthen we know that the columns of \\(\\rmU\\) are made by the eigenvalues of \\(A A^T\\):\n$ \\[\\begin{align*}\nA A^T &= \\left[\\begin{array}{cccc}\n  20 & 14 & 0 & 0 \\\\\n  14 & 10 & 0 & 0 \\\\\n  0 & 0 & 0 & 0 \\\\\n  0 & 0 & 0 & 0 \\\\\n\\end{array}\\right]\\\\\n\\rmU &= \\left[\\begin{array}{cccc}\n  0.82 & -0.58 & 0 & 0 \\\\\n  0.58 & 0.82 & 0 & 0 \\\\\n  0 & 0 & 1 & 0 \\\\\n  0 & 0 & 0 & 1 \\\\\n\\end{array}\\right]\n\\end{align*}\\] $\nsimilarly, the right singular vectors are obtained as eigenvalues of \\(A^T A\\):\n$ \\[\\begin{align*}\nA^T A &= \\left[\\begin{array}{cc}\n  5 & 11 \\\\\n  11 & 25\\\\\n\\end{array}\\right]\\\\\n\\rmV &= \\left[\\begin{array}{cc}\n  0.4 & -0.91 \\\\\n  0.91 & 0.4\n\\end{array}\\right]\n\\end{align*}\\] $\ninstead, \\(\\rmS\\) is formed by the squared root of the eivenvectors of \\(\\rmV\\) or \\(\\rmU\\):\n$ = $"
  }
]